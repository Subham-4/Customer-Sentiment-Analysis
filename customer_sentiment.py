# -*- coding: utf-8 -*-
"""Customer_Sentiment.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1R8L1Kpuq6TKioT67rC9ARBAsv6FAKzLV
"""

import numpy as np
import pandas as pd
from xgboost import XGBClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix, ConfusionMatrixDisplay
from sklearn.preprocessing import StandardScaler
from matplotlib import pyplot as plt
from tensorflow.keras.layers import InputLayer, Dense, Activation,Dropout
from tensorflow.keras.models import Sequential
from tensorflow.keras.optimizers import Adam
import tensorflow as tf

df = pd.read_csv('/content/Data Vortex_Round 2.csv')
df.head()

df['Age'] = 0
for i in range(df.shape[0]):
  df['Age'][i] = 2023 - int(df['DtCustomer'][i][6:10])

df.head()

df = df.drop('DtCustomer',axis=1)
df.head()

df['Marital'].unique()

df['Marital'].value_counts()

df['Marital'] = df['Marital'].replace({'Single': 'Alone', 'Widowed': 'Alone', 'Divorced': 'Alone', 'Separated': 'Alone'})

df['Education'].unique()

df['Education'].value_counts()

df['Education'] = df['Education'].replace({'Bachelors': 'Degree', 'Masters': 'Degree', 'PhD': 'Degree', 'None': 'No Degree', 'High School': 'No Degree'})

df['Child'] = df['Kidhome'] + df['Teenhome']

df['Spending']=df['MntWines'] + df['MntFruits'] + df['MntMeatProducts'] + df['MntFishProducts'] + df['MntSweetProducts'] + df['MntGoldProds']

df['Purchases'] = df['NumCatalogPurchases'] + df['NumStorePurchases'] + df['NumWebPurchases'] + df['NumDealsPurchases']

df["NumCmpResponce"] = df[["AcceptedCmp1", "AcceptedCmp2", "AcceptedCmp3",
                                 "AcceptedCmp4", "AcceptedCmp5", "Response"]].sum(axis=1)

df = df[['Age', 'Education', 'Marital', 'Child', 'Income', 'Spending', 'Purchases', 'NumWebVisitsMonth', 'Recency', 'NumCmpResponce', 'Complain', 'Response']]
df.head()

df.isnull().sum()

# Commented out IPython magic to ensure Python compatibility.
# %%capture
# Education = df['Education'].unique()
# 
# for i in range(df.shape[0]):
#   if df['Education'][i] == Education[0]:
#     df['Education'][i] = 0
#   elif df['Education'][i] == Education[1]:
#     df['Education'][i] = 1
#   else:
#     df['Education'][i] = 2

# Commented out IPython magic to ensure Python compatibility.
# %%capture
# Marital = df['Marital'].unique()
# 
# for i in range(df.shape[0]):
#   if df['Marital'][i] == Marital[0]:
#     df['Marital'][i] = 0
#   else:
#     df['Marital'][i] = 1

df.head()

x_data = df.iloc[:, df.columns != 'Response' ]
# x_data = df.iloc[:,:5]
y_data = df.iloc[:, df.columns == 'Response']

x_data.shape, y_data.shape

train_x, test_x, train_y, test_y = train_test_split(x_data, y_data, test_size=0.2, random_state = 0, shuffle = True)

scaler = StandardScaler()
train_data = scaler.fit_transform(train_x)
test_data=scaler.fit_transform(test_x)

"""XGBOOST CLASSIFIER"""

model = XGBClassifier(n_estimators = 200, max_depth=3, subsample=0.8, learning_rate=0.01, gamma=0.01, colsample_bytree = 1, objective = "binary:logistic", random_state = 1)

model.fit(train_data, train_y)

predict_train = model.predict(train_data)
predict_test = model.predict(test_data)

train_acc = accuracy_score(train_y, predict_train)
test_acc = accuracy_score(test_y, predict_test)

train_acc, test_acc

f1_score(train_y, predict_train)

f1_score(test_y, predict_test)

conf_mat = confusion_matrix(test_y, predict_test)
cm_display = ConfusionMatrixDisplay(confusion_matrix = conf_mat, display_labels = ['NO', 'YES'])
cm_display.plot()
plt.show()

"""NEURAL NETWORK"""

classifier = Sequential()
classifier.add(Dense(units = 512, activation = 'relu', input_dim = 11))
classifier.add(Dense(units = 512, activation = 'relu'))
classifier.add(Dropout(0.2))
classifier.add(Dense(units = 256, activation = 'relu'))
classifier.add(Dropout(0.2))
classifier.add(Dense(units = 128, activation = 'relu'))
classifier.add(Dropout(0.2))
classifier.add(Dense(units = 128, activation = 'relu'))
classifier.add(Dense(units = 1, activation = 'sigmoid'))
classifier.compile(optimizer = Adam(learning_rate=0.0001), loss = 'binary_crossentropy', metrics = ['accuracy'])
classifier.fit(train_data, train_y, epochs = 30)

predict_train = classifier.predict(train_data)
predict_test = classifier.predict(test_data)

for i in range(predict_train.shape[0]):
  if predict_train[i]>0.6:
    predict_train[i] = 1
  else:
    predict_train[i] = 0

for i in range(predict_test.shape[0]):
  if predict_test[i]>0.6:
    predict_test[i] = 1
  else:
    predict_test[i] = 0

train_acc = accuracy_score(train_y, predict_train)
test_acc = accuracy_score(test_y, predict_test)

train_acc, test_acc

f1_score(train_y, predict_train)

f1_score(test_y, predict_test)

conf_mat = confusion_matrix(test_y, predict_test)
cm_display = ConfusionMatrixDisplay(confusion_matrix = conf_mat, display_labels = ['NO', 'YES'])
cm_display.plot()
plt.show()

"""LOGISTIC REGRESSION"""

model = LogisticRegression()

# Train the model
model.fit(train_x, train_y)

# Make predictions on the test set
y_pred = model.predict(test_x)

# Evaluate the model
print("Accuracy:", accuracy_score(test_y, y_pred))
print("Classification Report:")
print(classification_report(test_y, y_pred))

"""KNN"""

from sklearn.neighbors import KNeighborsClassifier

k=2
neigh=KNeighborsClassifier(n_neighbors=k).fit(train_x,train_y)
yhat=neigh.predict(test_x)

from sklearn import metrics
print("Train set Accuracy: ", metrics.accuracy_score(train_y, neigh.predict(train_x)))
print("Test set Accuracy: ", metrics.accuracy_score(test_y, yhat))